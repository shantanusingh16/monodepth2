{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/scratch/kaustubh/jaidev/HabitatSemantics/new_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1pXnuDYAj8r',\n",
       " '5LpN3gDmAk7',\n",
       " '29hnd4uzFmX',\n",
       " '5ZKStnWn8Zo',\n",
       " '2azQ1b91cZZ',\n",
       " '2n8kARJN3HM',\n",
       " '1LXtFkjw3qL',\n",
       " '2t7WUuJeko7',\n",
       " '5q7pvUzZiYa',\n",
       " '17DRP5sb8fy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_folders = os.listdir(data_dir)\n",
    "avail_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/storage/Projects/Indoor-SfMLearner/splits/habitat_train_depth.txt', 'r') as f:\n",
    "    train_indoorsfm_files = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_habitat_files = set()\n",
    "for row in train_indoorsfm_files:\n",
    "    files = sorted(row.replace('\\n','').split(' '), key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "    for idx in range(1, len(files) - 1):\n",
    "        foldername = files[idx].split('/')[0]\n",
    "        if foldername not in avail_folders:\n",
    "            continue\n",
    "        train_habitat_files.add('{} {}'.format(foldername, os.path.splitext(os.path.basename(files[idx]))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/storage/Projects/monodepth2/splits/habitat/train_files.txt', 'w') as f:\n",
    "    f.writelines([filename+'\\n' for filename in train_habitat_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/storage/Projects/Indoor-SfMLearner/splits/habitat_test_depth.txt', 'r') as f:\n",
    "    val_indoorsfm_files = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_habitat_files = set()\n",
    "for row in val_indoorsfm_files:\n",
    "    filename = row.replace('\\n','').split(' ')[0]\n",
    "    foldername = filename.split('/')[0]\n",
    "    if foldername not in avail_folders:\n",
    "        continue\n",
    "    val_habitat_files.add('{} {}'.format(foldername, os.path.splitext(os.path.basename(filename))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/storage/Projects/monodepth2/splits/habitat/val_files.txt', 'w') as f:\n",
    "    f.writelines([filename+'\\n' for filename in val_habitat_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fresh split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(avail_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29hnd4uzFmX',\n",
       " '5q7pvUzZiYa',\n",
       " '2azQ1b91cZZ',\n",
       " '17DRP5sb8fy',\n",
       " '5LpN3gDmAk7',\n",
       " '1LXtFkjw3qL',\n",
       " '2t7WUuJeko7',\n",
       " '5ZKStnWn8Zo',\n",
       " '1pXnuDYAj8r',\n",
       " '2n8kARJN3HM']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.7\n",
    "train_len = int(len(avail_folders) * train_test_split)\n",
    "train_folders = avail_folders[: train_len]\n",
    "val_folders = avail_folders[train_len: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8530"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "train_habitat_files = list()\n",
    "\n",
    "for foldername in train_folders:\n",
    "    depth_dir = os.path.join(data_dir, foldername, '0', 'left_depth')\n",
    "    filenames = sorted(os.listdir(depth_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    invalid_files = set()\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        depth_arr = np.array(Image.open(os.path.join(depth_dir, filename))).astype(np.float32) / 1000\n",
    "        if np.max(depth_arr) - np.min(depth_arr) < threshold:\n",
    "            invalid_files.add(idx)\n",
    "    for idx in range(1, len(filenames) - 1):\n",
    "        if (idx - 1 in invalid_files) or (idx in invalid_files) or (idx + 1 in invalid_files):\n",
    "            continue\n",
    "        train_habitat_files.append('{} {}'.format(foldername, os.path.splitext(filenames[idx])[0]))\n",
    "    \n",
    "len(train_habitat_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../splits/habitat/train_files.txt', 'w') as f:\n",
    "    f.writelines([filename+'\\n' for filename in train_habitat_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7336"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "val_habitat_files = list()\n",
    "\n",
    "for foldername in val_folders:\n",
    "    depth_dir = os.path.join(data_dir, foldername, '0', 'left_depth')\n",
    "    filenames = sorted(os.listdir(depth_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    invalid_files = set()\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        depth_arr = np.array(Image.open(os.path.join(depth_dir, filename))).astype(np.float32) / 1000\n",
    "        if np.max(depth_arr) - np.min(depth_arr) < threshold:\n",
    "            invalid_files.add(idx)\n",
    "    for idx in range(1, len(filenames) - 1):\n",
    "        if (idx - 1 in invalid_files) or (idx in invalid_files) or (idx + 1 in invalid_files):\n",
    "            continue\n",
    "        val_habitat_files.append('{} {}'.format(foldername, os.path.splitext(filenames[idx])[0]))\n",
    "    \n",
    "len(val_habitat_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../splits/habitat/val_files.txt', 'w') as f:\n",
    "    f.writelines([filename+'\\n' for filename in val_habitat_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
